# -*- coding: utf-8 -*-
"""Linear_Regression & PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ix-RmLgCzy2ly8Nc74V208sgysfamGEP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

url = r"/Users/adityapc/Downloads/automobile_data (1) (1).csv"
df = pd.read_csv(url)

"""# ***DATA CLEANING***"""

df.shape

df.dtypes

df.head(5)

df.replace('?', np.nan, inplace=True)

df.isnull().sum()

x = df.isnull().sum()/len(df) *100
x = x[x>0]
print(x)

df[df['bore'].isnull()]

df.dropna(subset = ['bore','num-of-doors','stroke','horsepower','peak-rpm','price'], inplace=True)
df.reset_index(drop=True, inplace=True)

df.shape
#lost only 8 rows

df['normalized-losses'].fillna(0, inplace = True)

#CONVERTING DATATYPE
df['normalized-losses'] =df['normalized-losses'].astype(int)

df['normalized-losses'].fillna(df['normalized-losses'].mean(), inplace = True)

x = df.isnull().sum()
x[x>0]

dict = {'two':2, 'four':4}
df['num-of-doors'] = df['num-of-doors'].replace(dict)

#CONVERTING DATA TYPE
df['num-of-doors'] = df['num-of-doors'].astype(int)

df['make'].value_counts()

df['body-style'].value_counts()

df['num-of-cylinders'].unique()

#REPLACING STRING VALUES/OBJECTS WITH NUMERICAL VALUES
dict = {'four':4, 'six':6, 'five':5, 'three':3, 'twelve':12, 'eight':8}
df['num-of-cylinders'] = df['num-of-cylinders'].replace(dict)

#CONVERTING DATATYPES
df['num-of-cylinders'] = df['num-of-cylinders'].astype(int)

#CONVERTIN DATATYPES
df['bore'] = df['bore'].astype(float)
df['stroke'] = df['stroke'].astype(float)
df['price'] = df['price'].astype(float)
df['horsepower'] = df['horsepower'].astype(int)
df['peak-rpm'] = df['peak-rpm'].astype(int)
df['highway-mpg'] = df['highway-mpg'].astype(float)
df['city-mpg'] = df['city-mpg'].astype(float)

df.dtypes

"""***CORRELATION***"""

corr_cols = ['horsepower', 'peak-rpm', 'city-mpg','highway-mpg','price','num-of-cylinders']

corr = df[corr_cols].corr()

plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""**OBSERVATION 1**

*   ***from this heatmap it was observed that higher the highway mileage, lower the price, showing moderate to high inverse correlation between price and highway mpg***
*   ***the inverse correlation between city mileage and price was also observed, the correlation coefficient is moderate to high***
*   ***inverse relationship between horsepower and mileage can also be observed***




"""

df['make'].value_counts().plot(kind='pie', figsize=(10,10), autopct='%1.1f%%', startangle = 180)
plt.title("Category Distribution")
plt.ylabel('')
plt.show()

"""**OBSERVATION 2**

***toyota has the highest percentage of automobile in the given data***
"""

df.head(5)

df = df.reset_index()

"""*GROUPING BY MAKE AND FINDING MEAN PRICE*"""

mean_price = df.groupby('make')['price'].mean()

mean_price = mean_price.sort_values(ascending=False)

mean_price = mean_price.to_frame()

mean_price = mean_price.reset_index()

sns.barplot(x='make', y='price', data=mean_price)
plt.title('Mean Price by Manufacturers')
plt.xlabel('Make Company')
plt.xticks(rotation=90)
plt.ylabel('Average Price')

df_symbolling = df.sort_values('symboling',ascending = False)

sns.kdeplot(df_symbolling['symboling'], shade=True)
plt.show()

"""***KDE graph to observe the likeliness of which symboling***"""

plt.figure(figsize = (12,10))
sns.barplot(x = 'make', y = 'price', hue='body-style', data = df)
plt.xlabel('Make')
plt.ylabel('Count')
plt.title('Body Style Counts by Make')
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize = (8,6))
sns.histplot(x='make', hue='num-of-doors', data=df, palette='dark', multiple = 'dodge', )
plt.xlabel('Make')
plt.ylabel('Count')
plt.title('Histogram plot by make with number of doors')
plt.xticks(rotation=90)
plt.show()
#why are there extra colours?

df.dtypes

"""***another correlation***"""

corr_cols = ['curb-weight','engine-size','horsepower','price']

corr = df[corr_cols].corr()

sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""***Heavy to moderate proportional correlation between horsepower, engine-size, curb-weight and price***"""

df.dtypes

"""# ***ONE HOT ENCODING***"""

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False, drop='first')

encoded_cols = encoder.fit_transform(df[['make', 'fuel-type','aspiration','body-style','drive-wheels','engine-location','engine-type','fuel-system']])

one_hot_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(['make', 'fuel-type','aspiration','body-style','drive-wheels','engine-location','engine-type','fuel-system']))

df_encoded = pd.concat([df, one_hot_df], axis=1)

df_encoded = df_encoded.drop(['make', 'fuel-type','aspiration','body-style','drive-wheels','engine-location','engine-type','fuel-system'], axis = 1)

df_encoded.dtypes

df_encoded.drop('index', axis=1, inplace=True)

df_encoded.shape

corr = df_encoded.corr()

"""*slightly jumbled heatmap after one hot encoding*"""

plt.figure(figsize = (15,10))
sns.heatmap(corr, annot = True)
plt.show()

"""# **PCA**"""

from sklearn.decomposition import PCA

pca = PCA()

df_encoded.columns

features = ['symboling', 'normalized-losses', 'num-of-doors', 'wheel-base',
       'length', 'width', 'height', 'curb-weight', 'num-of-cylinders',
       'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower',
       'peak-rpm', 'city-mpg', 'highway-mpg', 'make_audi', 'make_bmw',
       'make_chevrolet', 'make_dodge', 'make_honda', 'make_isuzu',
       'make_jaguar', 'make_mazda', 'make_mercedes-benz', 'make_mercury',
       'make_mitsubishi', 'make_nissan', 'make_peugot', 'make_plymouth',
       'make_porsche', 'make_saab', 'make_subaru', 'make_toyota',
       'make_volkswagen', 'make_volvo', 'fuel-type_gas', 'aspiration_turbo',
       'body-style_hardtop', 'body-style_hatchback', 'body-style_sedan',
       'body-style_wagon', 'drive-wheels_fwd', 'drive-wheels_rwd',
       'engine-location_rear', 'engine-type_l', 'engine-type_ohc',
       'engine-type_ohcf', 'engine-type_ohcv', 'fuel-system_2bbl',
       'fuel-system_idi', 'fuel-system_mfi', 'fuel-system_mpfi',
       'fuel-system_spdi', 'fuel-system_spfi']

x = df_encoded.loc[:,features].values

y = df_encoded.loc[:,'price'].values

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

scaled_data = sc.fit(x)

scaled_data = sc.transform(x)

pca.fit(scaled_data)

"""***figuring out the number of components using explained variance ratio***"""

plt.figure(figsize=(12,6))
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of components')
plt.ylabel('Cumulative explained variance')
plt.show()

"""***somewhere between 18-25 components gives a 80%-90% retained variance***"""

pca = PCA(n_components = 20)

pca.fit(scaled_data)

x_pca = pca.transform(scaled_data)

x_pca = pd.DataFrame(x_pca)

x_pca

plt.figure(figsize=(10,6))
plt.scatter(x_pca[0], x_pca[1],c = df_encoded['price'])
plt.xlabel('Principal Component 2')
plt.ylabel('Principal Component 3')

finalDF  = pd.concat([x_pca, df_encoded[['price']]], axis = 1)

finalDF.head(5)

pca.explained_variance_ratio_

0.19076767 + 0.09635071 + 0.06199693 + 0.05621396 + 0.04356302 + 0.03940753 + 0.03771462 + 0.03544266 + 0.03015795 + 0.02900351 + 0.02864478 + 0.02584932 + 0.02508687 + 0.02378763 + 0.0220795 + 0.02061783 + 0.01972521 + 0.01950361 + 0.01900339 + 0.01860097

x_pca.shape

finalDF.shape

"""# **LINEAR REGRESSION**
***train test split***
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(finalDF.drop('price', axis = 1) , finalDF['price'] , train_size=0.7, random_state = 30)

X_train

"""***fit regression***"""

from sklearn.linear_model import LinearRegression

reg = LinearRegression()

reg.fit(X_train, y_train)

y_pred = reg.predict(X_test)

sns.displot(y_test - y_pred, kind = 'kde')

# df_compare_new = pd.DataFrame(y_test)

# df_compare_new.reset_index(drop = True)

# DF = pd.DataFrame(y_pred)

# DF.reset_index(drop = True)

# concat_df = pd.concat([df_compare_new, DF], axis=1)

# concat_df.columns = ['price', 'target']

# concat_df

# plt.plot(concat_df['price'], label='Actual Values')
# plt.plot(concat_df['target'], label='Predicted Values')
# plt.legend()
# plt.xticks(rotation=20)
# plt.ylabel('Values')
# plt.title('Actual vs. Predicted Values')
# plt.show()

"""***checking metrics***"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mse = mean_squared_error(y_test, y_pred)

mae = mean_absolute_error(y_test, y_pred)

mse

mae

r2 = r2_score(y_test, y_pred)

r2

"""**good r2 score value (0.8 - 1)**

# **SAVING MODEL**
"""

import joblib

joblib.dump({'pca': pca, 'regression': reg}, 'model_pca_regression')
